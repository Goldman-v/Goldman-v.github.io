<!DOCTYPE html>
<html lang="zh-CN">

<title>RuiwenGaze</title>

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- 3.6.0最新 -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>

    <!-- bootstrap 4.6.1 -->
    <link rel="stylesheet" href="../../resource/bootstrap/dist/css/bootstrap.min.css">
    <script src="../../resource/bootstrap/dist/js/bootstrap.min.js"></script>


    <!-- tocbot 4.12.3 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.css">
    <script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script>
    <!-- 引用自己的库 -->
    <link rel="stylesheet" href="../../resource/css/cite.css">

    <script src="../../resource/js/cite.js"></script>
    <link rel="shortcut icon" href="../../resource/img/eeg-icon-black.svg">
</head>


<body style="font-family: '微软雅黑';background-color: #f5f7fa;">

    <div class="container">
        <div class="row">
            <div>
                <a href="../../index.html">
                    <img src="../../resource/img/logo2.png" alt="" class="img-fluid">
                </a>
            </div>
        </div>
    </div>


    <nav class="nav navbar-expand-md navbar-dark bg-dark">
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <div class="col-12">
                <ul class="navbar-nav text-center">
                    <li class="nav-item col-md-3">
                        <a class="nav-link" href="../../index.html">首页</span></a>
                    </li>
                    <li class="nav-item active col-md-3">
                        <a class="nav-link" href="index.html">Home</span></a>
                    </li>
                    <li class="nav-item col-md-3">
                        <a class="nav-link" href="download.html">DownLoad</a>
                    </li>
                    <li class="nav-item col-md-3">
                        <a class="nav-link" href="readme.html">Readme</a>
                    </li>
                </ul>
            </div>

        </div>
    </nav>

    <div class="container">
        <div class="row">
            <div class="col-2">
            </div>
            <div class="col-8 js-toc-content text-justify" style="font-size: 1em;">
                <img src="./resource/img/expriment_process.jpg" class="img-fluid" />
                <h2 style="font-size: 2em;margin-top: 5px;">
                    Abstract
                </h2>
                One major challenge in appearance-based gaze estimation is the lack of high-quality labeled data.
                Establishing databases
                or datasets is a way to obtain accurate gaze data and test methods or tools. However, the methods of
                collecting data in
                existing databases are designed on artificial chasing target tasks or unintentional free-looking
                tasks, which are not
                natural and real eye interactions and cannot reflect the inner cognitive processes of humans. To
                fill this gap, we
                propose the first gaze estimation dataset collected from an actual psychological experiment by the
                eye tracker, called
                the RavenGaze dataset. We design an experiment employing Raven's Matrices as visual stimuli and
                collecting gaze data,
                facial videos as well as screen content videos simultaneously. Thirty-four participants were
                recruited. The results show
                that the existing algorithms perform well on our RavenGaze dataset in the 3D and 2D gaze estimation
                task, and
                demonstrate good generalization ability according to cross-dataset evaluation task. RavenGaze and
                the establishment of
                the benchmark lay the foundation for other researchers to do further in-depth research and test
                their methods or tools.<br>
                <strong> Click <a href="readme.html">here</a> to know the details about the dataset.</strong>
                <br>
                <br>
                <h2>
                    How to use
                </h2>
                If you are interested in using this dataset, you will have to print, sign and scan an EULA (End User
                License Agreement) and upload it via the dataset request form. We will then supply you with a
                username
                and password to download the data. Please head on over to the downloads page or click <a
                    href="download.html">here</a> for more details.
                <br>
                <br>
                <h2>
                    Credits
                </h2>
                First and foremost we'd like to thank the all(34) participants in this study for having the patience
                and
                goodwill to let us record their data.
                This dataset was collected by:

                Intelligent Interaction Laboratory @ Northwestern Polytechnical University

            </div>
            <div class="col-mb-12 col-2 kit-hidden-tb post-toc-content">
                <div id="toc-container" class="post-toc">
                    <div class="toc"></div>
                </div>
            </div>
        </div>
    </div>


    <footer class="container-fluid" id="footer">
        <div class="row bottomPage">
            <div class="col-6 text-white text-center mt-3">
                <p class="small">邮箱：xutao@nwpu.edu.cn</p>
                <p class="small">地址：西安市长安区东祥路1号</p>
            </div>
            <div class="col-6 text-center mt-3">
                <small class="d-block mb-3 text-muted">Intelligent Interaction Laboratory @ NWPU</small>

                <small class="d-block mb-3 text-muted">All Rights Reserved © 2019-<div id="year"
                        style="display: inline-block">
                        LastYear
                    </div></small>
            </div>

        </div>

    </footer>


</body>


<script language="javascript" type="text/javascript">
    add_head_id();

    tocify();

    footer_year();
</script>


</html>